# Models for [Language]

## Embedings

| Model Name | Paper | Source |
|------ | ----- | ---- |
| Jina v3 | [Link](https://arxiv.org/abs/2409.10173) | [Link](https://huggingface.co/jinaai/jina-embeddings-v3)|
| Jina ColBERT v2 | [Link](https://huggingface.co/papers/2408.16672) | [Link](https://huggingface.co/jinaai/jina-colbert-v2)|
| GTE Multilingual | [Link](https://arxiv.org/pdf/2407.19669) | [Link](https://huggingface.co/Alibaba-NLP/gte-multilingual-base) |
| Paraphrase Multilingual MiniLM-L12 v2 | [Link](https://huggingface.co/papers/1908.10084) | [Link](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) |
| Paraphrase Multilingual mpnet v2 | [Link](https://huggingface.co/papers/1908.10084) | [Link](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2) |
| LaBSE | [Link](https://arxiv.org/abs/2007.01852) | [Link](https://huggingface.co/sentence-transformers/LaBSE) |
| distiluse-base-multilingual-cased-v2 | [Link](https://huggingface.co/papers/1908.10084) | [Link](https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v2) |
| ColBERT-XM | [Link](https://huggingface.co/papers/2402.15059) | [Link](https://huggingface.co/antoinelouis/colbert-xm) |
| Multilingual E5 | [Link](https://huggingface.co/papers/2402.05672) | [Link](https://huggingface.co/intfloat/multilingual-e5-large) |
| LEALLA | [Link](https://huggingface.co/papers/2302.08387) | [Link](https://huggingface.co/setu4993/LEALLA-base) |
| BGE-M3 | [Link](https://huggingface.co/papers/2402.03216) | [Link](https://huggingface.co/BAAI/bge-m3) |
| Small E-Czech | - | [Link](https://huggingface.co/Seznam/small-e-czech) |

## Language Models (Encoder-only)

| Model Name | Paper | Source |
|------ | ----- | ---- |
| XLM-RoBERTa | [Link](https://huggingface.co/papers/1911.02116) | [Link](https://huggingface.co/FacebookAI/xlm-roberta-base) |
| mBERT | [Link](https://huggingface.co/papers/1810.04805) | [Link](https://huggingface.co/google-bert/bert-base-multilingual-uncased) |
| NeMO Megatron-mT5 | [Link](https://arxiv.org/pdf/1909.08053) | [Link](https://huggingface.co/nvidia/nemo-megatron-mt5-3B) |
| RemBERT | [Link](https://huggingface.co/papers/2010.12821) | [Link](https://huggingface.co/google/rembert) |
| XMOD | [Link](https://aclanthology.org/2022.naacl-main.255/) | [Link](https://huggingface.co/facebook/xmod-base) |
| XLM-V | [Link](https://huggingface.co/papers/2301.10472) | [Link](https://huggingface.co/facebook/xlm-v-base) |
| EUBERT | - | [Link](https://huggingface.co/EuropeanParliament/EUBERT) |
| CZERT | [Link](https://aclanthology.org/2021.ranlp-1.149) | [Link](https://huggingface.co/UWB-AIR/Czert-A-base-uncased) |
| FERNET-C5 | [Link](https://link.springer.com/chapter/10.1007/978-3-030-89579-2_3) | [Link](https://huggingface.co/fav-kky/FERNET-C5) |

## Large Language Models

| Model Name | Paper | Source |
|------ | ----- | ---- |
| Kurage | - | [Link](https://huggingface.co/lightblue/kurage-multilingual) |
| mT5 | [Link](https://huggingface.co/papers/2010.11934) | [Link](https://huggingface.co/google/mt5-base) |
| mT0 | [Link](https://huggingface.co/papers/2211.01786) | [Link](https://huggingface.co/bigscience/mt0-xxl) |
| UMT5 | [Link](https://openreview.net/forum?id=kXwdL1cWOAi) | [Link](https://huggingface.co/google/umt5-xl) |
| Nemotron | - | [Link](https://huggingface.co/nvidia/nemotron-3-8b-base-4k) |
| EuroGPT2 | - | [Link](https://huggingface.co/DFKI-SLT/eurogpt2) |
| GPT-2B-001 | [Link](https://huggingface.co/papers/1909.08053) | [Link](https://huggingface.co/nvidia/GPT-2B-001) |
| UMT5 | [Link](https://openreview.net/forum?id=kXwdL1cWOAi) | [Link](https://huggingface.co/google/umt5-base) |
| CzeGPT-2 | [Link](https://ieeexplore.ieee.org/document/10453575) | [Link](https://huggingface.co/MU-NLPC/CzeGPT-2) |
| Czech GPT-2 XL | - | [Link](https://huggingface.co/BUT-FIT/Czech-GPT-2-XL-133k) |
| CSTinyLlama-1.2B | - | [Link](https://huggingface.co/BUT-FIT/CSTinyLlama-1.2B) |
| CSMPT7B | - | [Link](https://huggingface.co/BUT-FIT/csmpt7b) |

## Machine Translation

| Model Name | Paper | Source |
|------ | ----- | ---- |
| NLLB-200 | [Link](https://arxiv.org/abs/2207.04672) | [Link](https://huggingface.co/facebook/nllb-200-3.3B) |
| MADLAD-400 | [Link](https://huggingface.co/papers/2309.04662) | [Link](https://huggingface.co/google/madlad400-3b-mt) |
| Seamless M4T v2 | [Link](https://huggingface.co/papers/2312.05187) | [Link](https://huggingface.co/facebook/seamless-m4t-v2-large) |
| M2M-100 | [Link](https://huggingface.co/papers/2010.11125) | [Link](https://huggingface.co/facebook/m2m100_1.2B) |
| SMALL-100 | [Link](https://huggingface.co/papers/2210.11621) | [Link](https://huggingface.co/alirezamsh/small100) |

## Speech Recognition Models

| Model Name | Paper | Source |
|------ | ----- | ---- |
| Whisper v3 | [Link](https://huggingface.co/papers/2212.04356) | [Link](https://huggingface.co/openai/whisper-large-v3) |
